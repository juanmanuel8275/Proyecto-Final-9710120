{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "import datetime\n",
    "import boto3\n",
    "import psycopg2\n",
    "import configparser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iniciación de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_clientes = np.random.randint(500, 1000) #cantidad de clientes a crear\n",
    "rdsIdentifier = 'proyecto' #nombre de la instancia\n",
    "fake = Faker() #inicialización para creación de data random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos archivo de configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proy_escec.cfg']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('proy_escec.cfg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos Instancia de RDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_conn = boto3.client('rds', aws_access_key_id=config.get('IAM', 'ACCESS_KEY'),\n",
    "                    aws_secret_access_key=config.get('IAM', 'SECRET_ACCESS_KEY'),\n",
    "                    region_name='us-east-1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificamos Instancias de RDS disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBInstanceIds ['dw', 'proyecto']\n"
     ]
    }
   ],
   "source": [
    "rdsInstanceIds = []\n",
    "\n",
    "response = aws_conn.describe_db_instances()\n",
    "for resp in response['DBInstances']:\n",
    "    rdsInstanceIds.append(resp['DBInstanceIdentifier'])\n",
    "    db_instance_status = resp['DBInstanceStatus']\n",
    "\n",
    "print(f\"DBInstanceIds {rdsInstanceIds}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación de Servicio RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Instancia de Base de Datos ya Existe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = aws_conn.create_db_instance(\n",
    "            AllocatedStorage=10,\n",
    "            DBName=config.get('RDS', 'DB_NAME'),\n",
    "            DBInstanceIdentifier=rdsIdentifier,\n",
    "            DBInstanceClass=\"db.t3.micro\",\n",
    "            Engine=\"postgres\",\n",
    "            MasterUsername=config.get('RDS', 'DB_USER'),\n",
    "            MasterUserPassword=config.get('RDS', 'DB_PASSWORD'),\n",
    "            Port=int(config.get('RDS', 'DB_PORT')),\n",
    "            VpcSecurityGroupIds=[config.get('VPC', 'SECURITY_GROUP')],\n",
    "            PubliclyAccessible=True\n",
    "        )\n",
    "    print(response)\n",
    "except aws_conn.exceptions.DBInstanceAlreadyExistsFault as ex:\n",
    "    print(\"La Instancia de Base de Datos ya Existe.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recordemos Esperar unos minutos para consultar la informaicón de la instancia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtenemos URL del Host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proyecto.cf32hjwhygka.us-east-1.rds.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "     instances = aws_conn.describe_db_instances(DBInstanceIdentifier=rdsIdentifier)\n",
    "     RDS_HOST = instances.get('DBInstances')[0].get('Endpoint').get('Address')\n",
    "     print(RDS_HOST)\n",
    "except Exception as ex:\n",
    "     print(\"La instancia de base de datos no existe o aun no se ha terminado de crear.\")\n",
    "     print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conexión a Base de Datos desde Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de Datos Creada Exitosamente\n"
     ]
    }
   ],
   "source": [
    "import Proy_sql_queries\n",
    "\n",
    "try:\n",
    "    db_conn = psycopg2.connect(\n",
    "        database=config.get('RDS', 'DB_NAME'), \n",
    "        user=config.get('RDS', 'DB_USER'),\n",
    "        password=config.get('RDS', 'DB_PASSWORD'), \n",
    "        host=RDS_HOST,\n",
    "        port=config.get('RDS', 'DB_PORT')\n",
    "    )\n",
    "\n",
    "    cursor = db_conn.cursor()\n",
    "    cursor.execute(Proy_sql_queries.DDL_QUERY)\n",
    "    db_conn.commit()\n",
    "    print(\"Base de Datos Creada Exitosamente\")\n",
    "except Exception as ex:\n",
    "    print(\"ERROR: Error al crear la base de datos.\")\n",
    "    print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insertamos Datos en tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertDataToSQL(data_dict, table_name):\n",
    "     postgres_driver = f\"\"\"postgresql://{config.get('RDS', 'DB_USER')}:{config.get('RDS', 'DB_PASSWORD')}@{RDS_HOST}:{config.get('RDS', 'DB_PORT')}/{config.get('RDS', 'DB_NAME')}\"\"\"    \n",
    "     df_data = pd.DataFrame.from_records(data_dict)\n",
    "     try:\n",
    "          response = df_data.to_sql(table_name, postgres_driver, index=False, if_exists='append')\n",
    "          print(f'Se han insertado {response} nuevos registros.' )\n",
    "     except Exception as ex:\n",
    "          print(ex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insertamos datos en Lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"lenguaje_pkey\"\n",
      "DETAIL:  Key (id_lenguaje)=(10) already exists.\n",
      "\n",
      "[SQL: INSERT INTO lenguaje (id_lenguaje, lenguaje) VALUES (%(id_lenguaje)s, %(lenguaje)s)]\n",
      "[parameters: ({'id_lenguaje': 10, 'lenguaje': 'español'}, {'id_lenguaje': 11, 'lenguaje': 'ingles'}, {'id_lenguaje': 12, 'lenguaje': 'portugues'})]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n"
     ]
    }
   ],
   "source": [
    "data_lenguaje = [\n",
    "     {'id_lenguaje': 10, 'lenguaje': 'español'}, \n",
    "     {'id_lenguaje': 11, 'lenguaje': 'ingles'}, \n",
    "     {'id_lenguaje': 12, 'lenguaje': 'portugues'}\n",
    "]\n",
    "\n",
    "#insertamos data en tabla lenguaje \n",
    "insertDataToSQL(data_lenguaje, 'lenguaje')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insertamos Data para Genero de libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"genero_pkey\"\n",
      "DETAIL:  Key (id_genero)=(20) already exists.\n",
      "\n",
      "[SQL: INSERT INTO genero (id_genero, genero) VALUES (%(id_genero)s, %(genero)s)]\n",
      "[parameters: ({'id_genero': 20, 'genero': 'suspenso'}, {'id_genero': 21, 'genero': 'terror'}, {'id_genero': 22, 'genero': 'superacion'}, {'id_genero': 23, 'genero': 'novela'})]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n"
     ]
    }
   ],
   "source": [
    "data_genero = [\n",
    "     {'id_genero': 20, 'genero': 'suspenso'}, \n",
    "     {'id_genero': 21, 'genero': 'terror'}, \n",
    "     {'id_genero': 22, 'genero': 'superacion'}, \n",
    "     {'id_genero': 23, 'genero': 'novela'}\n",
    "]\n",
    "\n",
    "insertDataToSQL(data_genero, 'genero')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insertamos Data para Autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"autor_pkey\"\n",
      "DETAIL:  Key (id_autor)=(30) already exists.\n",
      "\n",
      "[SQL: INSERT INTO autor (id_autor, autor) VALUES (%(id_autor)s, %(autor)s)]\n",
      "[parameters: ({'id_autor': 30, 'autor': 'Juan Soto'}, {'id_autor': 31, 'autor': 'Susana Rojas'}, {'id_autor': 32, 'autor': 'Pedro Fernandez'}, {'id_autor': 33, 'autor': 'Rocio Chacon'}, {'id_autor': 34, 'autor': 'Julio Quezada'})]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n"
     ]
    }
   ],
   "source": [
    "data_autor = [\n",
    "     {'id_autor': 30, 'autor': 'Juan Soto'}, \n",
    "     {'id_autor': 31, 'autor': 'Susana Rojas'}, \n",
    "     {'id_autor': 32, 'autor': 'Pedro Fernandez'}, \n",
    "     {'id_autor': 33, 'autor': 'Rocio Chacon'}, \n",
    "     {'id_autor': 34, 'autor': 'Julio Quezada'}\n",
    "]\n",
    "\n",
    "insertDataToSQL(data_autor, 'autor')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insertamos Data para Editorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"editorial_pkey\"\n",
      "DETAIL:  Key (id_editorial)=(40) already exists.\n",
      "\n",
      "[SQL: INSERT INTO editorial (id_editorial, editorial) VALUES (%(id_editorial)s, %(editorial)s)]\n",
      "[parameters: ({'id_editorial': 40, 'editorial': 'Libros Rotos'}, {'id_editorial': 41, 'editorial': 'Reflejos'}, {'id_editorial': 42, 'editorial': 'Profesional'}, {'id_editorial': 43, 'editorial': 'Educativa'})]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n"
     ]
    }
   ],
   "source": [
    "data_editorial = [\n",
    "     {'id_editorial': 40, 'editorial': 'Libros Rotos'}, \n",
    "     {'id_editorial': 41, 'editorial': 'Reflejos'},\n",
    "     {'id_editorial': 42, 'editorial': 'Profesional'},\n",
    "     {'id_editorial': 43, 'editorial': 'Educativa'}\n",
    "]\n",
    "\n",
    "insertDataToSQL(data_editorial, 'editorial')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insertamos Data para Sucursales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"sucursal_pkey\"\n",
      "DETAIL:  Key (id_sucursal)=(50) already exists.\n",
      "\n",
      "[SQL: INSERT INTO sucursal (id_sucursal, sucursal) VALUES (%(id_sucursal)s, %(sucursal)s)]\n",
      "[parameters: ({'id_sucursal': 50, 'sucursal': 'zona 10'}, {'id_sucursal': 51, 'sucursal': 'Centro civico'}, {'id_sucursal': 52, 'sucursal': 'Peten'}, {'id_sucursal': 53, 'sucursal': 'Quetzaltenango'})]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n"
     ]
    }
   ],
   "source": [
    "data_sucursal = [\n",
    "    {'id_sucursal': 50, 'sucursal': 'zona 10'},\n",
    "    {'id_sucursal': 51, 'sucursal': 'Centro civico'},\n",
    "    {'id_sucursal': 52, 'sucursal': 'Peten'},\n",
    "    {'id_sucursal': 53, 'sucursal': 'Quetzaltenango'}\n",
    "]\n",
    "insertDataToSQL(data_sucursal, 'sucursal')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insertamos Data para Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 812 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "data_cliente = []\n",
    "\n",
    "for cliente in range(cantidad_clientes):\n",
    "    clientProfile = fake.profile()\n",
    "    nuevo_cliente = {\n",
    "        'id_cliente': random.randint(10000000, 99999999),\n",
    "        'nombre': clientProfile['name'].split(' ')[0],\n",
    "        'apellido': clientProfile['name'].split(' ')[1],\n",
    "        'correo': clientProfile['mail'],\n",
    "        'telefono': clientProfile['ssn'],\n",
    "    }\n",
    "\n",
    "    data_cliente.append(nuevo_cliente)\n",
    "\n",
    "insertDataToSQL(data_cliente, 'cliente')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insertamos Data de Libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 93 nuevos registros.\n"
     ]
    }
   ],
   "source": [
    "cantidad_libros = np.random.randint(50,150)\n",
    "data_libros = []\n",
    "\n",
    "for book in range (cantidad_libros):\n",
    "    titulolibro = fake.profile()\n",
    "    nuevo_libro = {\n",
    "        'id_libro': random.randint(10000,99999),\n",
    "        'titulo' : titulolibro ['name'],\n",
    "        'id_lenguaje' : random.sample (data_lenguaje, 1)[0]['id_lenguaje'],\n",
    "        'id_genero' : random.sample (data_genero, 1)[0]['id_genero'],\n",
    "        'id_editorial' : random.sample (data_editorial, 1)[0]['id_editorial'],\n",
    "        'id_autor' : random.sample (data_autor, 1)[0]['id_autor']\n",
    "     }\n",
    "    \n",
    "    data_libros.append(nuevo_libro)\n",
    "insertDataToSQL(data_libros, 'libros')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insertamos Data de Orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"orden_pkey\"\n",
      "DETAIL:  Key (id_orden)=(0) already exists.\n",
      "\n",
      "[SQL: INSERT INTO orden (id_orden, fecha_hora, id_libro, id_sucursal, id_cliente) VALUES (%(id_orden)s, %(fecha_hora)s, %(id_libro)s, %(id_sucursal)s, %(id_cliente)s)]\n",
      "[parameters: ({'id_orden': 0, 'fecha_hora': datetime.datetime(2023, 2, 20, 15, 59, 10), 'id_libro': 90168, 'id_sucursal': 50, 'id_cliente': 60237074}, {'id_orden': 1, 'fecha_hora': datetime.datetime(2023, 3, 18, 2, 2, 38), 'id_libro': 94874, 'id_sucursal': 53, 'id_cliente': 28021022}, {'id_orden': 2, 'fecha_hora': datetime.datetime(2023, 3, 10, 20, 33, 10), 'id_libro': 94039, 'id_sucursal': 50, 'id_cliente': 23154873}, {'id_orden': 3, 'fecha_hora': datetime.datetime(2023, 2, 13, 16, 36, 56), 'id_libro': 28012, 'id_sucursal': 50, 'id_cliente': 78942456}, {'id_orden': 4, 'fecha_hora': datetime.datetime(2023, 2, 8, 1, 20, 45), 'id_libro': 50794, 'id_sucursal': 50, 'id_cliente': 31217532}, {'id_orden': 5, 'fecha_hora': datetime.datetime(2023, 4, 8, 8, 37, 37), 'id_libro': 85333, 'id_sucursal': 53, 'id_cliente': 83242002}, {'id_orden': 6, 'fecha_hora': datetime.datetime(2023, 4, 2, 22, 34, 13), 'id_libro': 53668, 'id_sucursal': 52, 'id_cliente': 78350102}, {'id_orden': 7, 'fecha_hora': datetime.datetime(2023, 3, 23, 23, 59, 41), 'id_libro': 67901, 'id_sucursal': 52, 'id_cliente': 29160439}  ... displaying 10 of 107 total bound parameter sets ...  {'id_orden': 105, 'fecha_hora': datetime.datetime(2023, 2, 25, 11, 13, 59), 'id_libro': 15304, 'id_sucursal': 51, 'id_cliente': 96654557}, {'id_orden': 106, 'fecha_hora': datetime.datetime(2023, 3, 20, 14, 20, 37), 'id_libro': 62086, 'id_sucursal': 52, 'id_cliente': 61420980})]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n"
     ]
    }
   ],
   "source": [
    "cantidad_ordenes = np.random.randint(100, 200)\n",
    "data_orden = []\n",
    "\n",
    "for orden in range(cantidad_ordenes):\n",
    "    nueva_orden = {\n",
    "            'id_orden': orden,\n",
    "            'fecha_hora': fake.date_time_this_year(),\n",
    "            \n",
    "            'id_libro': random.sample(data_libros, 1)[0]['id_libro'],\n",
    "            'id_sucursal':  random.sample(data_sucursal, 1)[0]['id_sucursal'],\n",
    "            'id_cliente': random.sample(data_cliente, 1)[0]['id_cliente']\n",
    "        }\n",
    "    \n",
    "    data_orden.append(nueva_orden)\n",
    "   \n",
    "insertDataToSQL(data_orden, 'orden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': 'Financial trader',\n",
       " 'company': 'Watts PLC',\n",
       " 'ssn': '292-33-6529',\n",
       " 'residence': '24786 Jenkins Radial\\nLake Ryan, AK 29057',\n",
       " 'current_location': (Decimal('35.5215225'), Decimal('-153.549317')),\n",
       " 'blood_group': 'A-',\n",
       " 'website': ['http://fisher.com/'],\n",
       " 'username': 'michellewolfe',\n",
       " 'name': 'Lori Crawford',\n",
       " 'sex': 'F',\n",
       " 'address': '113 Trevor Trail\\nPort Matthew, NM 75854',\n",
       " 'mail': 'owashington@gmail.com',\n",
       " 'birthdate': datetime.date(1940, 9, 22)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.profile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a36ac3473f4f765ee1d32c07f947cfa193603dbfd7ba2aa7bf3e12c57f78d587"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
